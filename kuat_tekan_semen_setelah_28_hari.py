# -*- coding: utf-8 -*-
"""1Kuat tekan semen setelah 28 hari.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pVNIvZRQ7A3vEt057sC-rrc63qxjbtPj
"""

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from scipy.stats import boxcox
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.model_selection import GridSearchCV

data = pd.read_excel('/content/PCC 18-19.xlsx')
data

data.isnull().sum()

data.drop('Tanggal', axis=1, inplace=True)

data

"""karena banyak angka 0 dimana pada variabel indepen nya adalah 0 lalu di target nya juga 0 dan distribusi angka 0 terlalu banyak. maka variabel dengan angka 0 dan target 0 dihapus  """

data = data.drop(data[data[[28]].eq(0).all(axis=1)].index)

data.describe()

data.loc[data[28] == 0].index.tolist()

data[data[28] > 1000]

indeks = [725]
data.drop(indeks, inplace=True)

data.describe()

data.corr()

"""# Memisahkan variabel yang akan digunakan dan di cleansing"""

variabel = data[['SiO2', 'Al203', 'Fe203', 'MgO',	'CaO',	'SO3',	'LOI',	'FL',	'Insol', 'Residu', 'Blaine', 28]]

variabel.describe()

variabel.corr()

variabel.columns

plt.figure(figsize = (20, 15))
plotnumber = 1

for col in variabel.columns:
    if plotnumber <= 12:
        ax = plt.subplot(4, 4, plotnumber)
        sns.boxplot(variabel[col])
        plt.xlabel(col, fontsize = 15)

    plotnumber += 1
plt.tight_layout()
plt.show()

variabel.skew()

plt.figure(figsize=(12, 10))
for i, col in enumerate(variabel.columns):
    plt.subplot(3, 4, i+1)
    sns.histplot(variabel[col], kde=True, color='skyblue')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.title('Distribution of {}'.format(col))

plt.tight_layout()
plt.show()

mean = variabel[28].mean()
std_dev = variabel[28].std()

threshold = 2
lower_bound = mean - threshold * std_dev
upper_bound = mean + threshold * std_dev

variabel = variabel[(variabel[28] >= lower_bound) & (variabel[28] <= upper_bound)]

variabel.shape

"""# Memisahkan kolom features dan target"""

target = variabel[28]

target = target.reset_index(drop=True)

target

features = variabel[['MgO', 'CaO', 'SO3', 'LOI',	'FL',	'Insol']]
features

"""**Normalisasi**

Outlier dan skewness
"""

features.skew()

target.skew()

plt.figure(figsize=(12, 10))
for i, col in enumerate(features.columns):
    plt.subplot(3, 4, i+1)
    sns.histplot(features[col], kde=True, color='skyblue')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.title('Distribution of {}'.format(col))

plt.tight_layout()
plt.show()

features = features.reset_index(drop=True)

features

plt.figure(figsize = (20, 15))
plotnumber = 1

for col in features.columns:
    if plotnumber <= 12:
        ax = plt.subplot(4, 4, plotnumber)
        sns.boxplot(features[col])
        plt.xlabel(col, fontsize = 15)

    plotnumber += 1
plt.tight_layout()
plt.show()

"""# split data"""

test_size = 0.4
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=42)

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# Model"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

modell = LinearRegression()

# Latih model dengan data
X = features
y = target
modell.fit(X, y)

# Lihat R-squared
r2 = modell.score(X, y)
print(f'R-squared (R^2): {r2:.4f}')

coefficients = modell.coef_
print("Koefisien Regresi:")
for feature, coef in zip(X.columns, coefficients):
    print(f"{feature}: {coef:.4f}")

coeff = np.array([-18.7519, 1.4187, 5.9347, -7.6158, -0.5737, -4.0594])
fitur = ['Mgo', 'CaO', 'SO3', 'LOI', 'FL', 'Insol']

plt.figure(figsize=(10, 6))
plt.barh(fitur, coeff, color='skyblue')
plt.xlabel('Koefisien Regresi')
plt.title('Pengaruh Linear Variabel terhadap Target')
plt.gca().invert_yaxis()  # Membalikkan urutan agar variabel teratas ditampilkan terlebih dahulu
plt.show()

"""memberikan visualisasi tentang seberapa besar kontribusi masing-masing variabel terhadap variabel target dalam model regresi linear. Jika koefisien positif, itu menunjukkan hubungan positif, dan jika koefisien negatif, itu menunjukkan hubungan negatif."""

import matplotlib.pyplot as plt
import numpy as np

coeff = np.array([-18.7519, 1.4187, 5.9347, -7.6158, -0.5737, -4.0594])
features = ['MgO', 'CaO', 'SO3', 'LOI', 'FL', 'Insol']

# Menentukan warna berdasarkan nilai koefisien
colors = ['red' if coef < 0 else 'green' for coef in coeff]

# Membuat plot barh dengan warna dinamis
plt.figure(figsize=(10, 6))
bars = plt.barh(features, coeff, color=colors)

# Menambahkan nilai koefisien pada setiap bar
for bar, val in zip(bars, coeff):
    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{val:.2f}', va='center', color='black')

# Menambahkan label dan judul
plt.xlabel('Koefisien Regresi')
plt.title('Pengaruh Linear Variabel terhadap Target')

# Membalikkan urutan pada sumbu y agar variabel teratas ditampilkan terlebih dahulu
plt.gca().invert_yaxis()

# Menampilkan grid
plt.grid(axis='x', linestyle='--', alpha=0.6)

plt.show()

XX = variabel[['SiO2', 'Al203', 'Fe203', 'MgO',	'CaO',	'SO3',	'LOI',	'FL',	'Insol', 'Residu', 'Blaine']]  # Gantilah dengan nama fitur yang sesuai
yy = target  # Gantilah dengan nama kolom target yang sesuai

XX.shape

yy.shape

modell.fit(XX, yy)

# Lihat R-squared
r2 = modell.score(XX, yy)
print(f'R-squared (R^2): {r2:.4f}')

"""nilai R-squared sebesar 0.4352 mengindikasikan bahwa model regresi yang telah Anda latih dapat menjelaskan sekitar 43.52% variabilitas dalam data target (variabel dependen) berdasarkan fitur-fitur yang digunakan.

regresi linier
"""

# Inisialisasi model
linear_model = LinearRegression()

# Latih model
linear_model.fit(X_train, y_train)

# Prediksi nilai target pada data uji
y_test_pred_linear = linear_model.predict(X_test)

# Evaluasi model
mse_linear = mean_squared_error(y_test, y_test_pred_linear)
r2_linear = r2_score(y_test, y_test_pred_linear)

print("Model: Linear Regression")
print(f"Mean Squared Error: {mse_linear}")
print(f"R-squared: {r2_linear}")

linear_model.score(X_train, y_train)

"""neural network"""

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(6,)),  # Input layer dengan 6 fitur
    tf.keras.layers.Dense(64, activation='relu'),  # Lapisan tersembunyi dengan 64 neuron dan fungsi aktivasi ReLU
    tf.keras.layers.Dense(1)  # Lapisan output dengan 1 neuron
])

model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=10, batch_size=32)

y_test_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_test_pred)
r2 = r2_score(y_test, y_test_pred)
print(f'Mean Squared Error: {mse:.4f}')
print(f'R-squared: {r2:.4f}')

"""mlp"""

from sklearn.neural_network import MLPRegressor #modul untuk membangun model regresi MLP
regr = MLPRegressor(random_state=1, max_iter=3000,hidden_layer_sizes=(5,3)).fit(X_train, y_train)
print('The R2 score of our prediction is %.4f' %(regr.score(X_test, y_test)))

param_grid = {
    'hidden_layer_sizes': [(5, 3), (10, 5), (20, 10)],
    'activation': ['relu', 'tanh'],
    'solver': ['adam', 'sgd'],
    'max_iter': [1000, 2000, 3000]
}

tun = MLPRegressor(random_state=1)

grid_search = GridSearchCV(regr, param_grid, cv=5, scoring='neg_mean_squared_error')

grid_search.fit(X_train, y_train)

pip install --upgrade scikit-learn

best = grid_search.best_estimator_

best.fit(X_train, y_train)

y_pred = best.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

r2 = r2_score(y_test, y_pred)

r2

# Gunakan model terbaik untuk membuat prediksi
y_pred_best = best.predict(X_test)

# Evaluasi performa model terbaik
mse_best = mean_squared_error(y_test, y_pred_best)
r2_best = r2_score(y_test, y_pred_best)

print(f'Mean Squared Error (Best Model): {mse_best:.4f}')
print(f'R-squared (Best Model): {r2_best:.4f}')

"""deep mlp"""

deepmlp = MLPRegressor(random_state=1, max_iter=3000,hidden_layer_sizes=(16,16,8,8)).fit(X_train, y_train)

from keras.utils import plot_model
plot_model(model, to_file='model.png', show_shapes=True)

print('The R2 score of our prediction is %.4f' %(deepmlp.score(X_test, y_test)))

predic = model.predict(X_test)

y_test = y_test.values.ravel()
predic = predic.ravel()
cek = pd.DataFrame({'Actual': y_test, 'Predicted': predic})
cek

eval = mean_squared_error(y_test, predic)

eval

param_grid = {
    'hidden_layer_sizes': [(16, 16, 8, 8), (32, 32, 16, 16), (64, 64, 32, 32)],
    'activation': ['relu', 'tanh', 'logistic'],
    'solver': ['adam', 'sgd'],
    'max_iter': [1000, 2000, 3000]
}

mod = MLPRegressor(random_state=1)

grid_search = GridSearchCV(mod, param_grid, cv=5, scoring='neg_mean_squared_error')

grid_search.fit(X_train, y_train)

bested = grid_search.best_estimator_
bested.fit(X_train, y_train)

hasil = bested.predict(X_test)

eror = mean_squared_error(y_test, y_pred)
rsquared = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {eror}')
print(f'R-squared (R^2) Score: {rsquared:.4f}')